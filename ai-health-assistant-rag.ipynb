{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q langchain\n!pip install -q torch\n!pip install -q transformers\n!pip install -q sentence-transformers\n\n!pip install bitsandbytes\n!pip install accelerate\n\n!pip install pinecone-client\n!pip install langchain-pinecone","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:16:29.820893Z","iopub.execute_input":"2024-02-10T09:16:29.821185Z","iopub.status.idle":"2024-02-10T09:18:25.553718Z","shell.execute_reply.started":"2024-02-10T09:16:29.821159Z","shell.execute_reply":"2024-02-10T09:18:25.552639Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.0.11 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.8.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mCollecting bitsandbytes\n  Downloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.11.4)\nRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy->bitsandbytes) (1.24.4)\nDownloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.42.0\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.26.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.24.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (23.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.20.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nCollecting pinecone-client\n  Downloading pinecone_client-3.0.2-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: certifi>=2019.11.17 in /opt/conda/lib/python3.10/site-packages (from pinecone-client) (2023.11.17)\nRequirement already satisfied: tqdm>=4.64.1 in /opt/conda/lib/python3.10/site-packages (from pinecone-client) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.10/site-packages (from pinecone-client) (4.9.0)\nRequirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from pinecone-client) (1.26.18)\nDownloading pinecone_client-3.0.2-py3-none-any.whl (201 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pinecone-client\nSuccessfully installed pinecone-client-3.0.2\nCollecting langchain-pinecone\n  Downloading langchain_pinecone-0.0.1-py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: langchain-core>=0.0.12 in /opt/conda/lib/python3.10/site-packages (from langchain-pinecone) (0.1.22)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-pinecone) (1.24.4)\nRequirement already satisfied: pinecone-client<4,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-pinecone) (3.0.2)\nCollecting simsimd<4.0.0,>=3.6.3 (from langchain-pinecone)\n  Downloading simsimd-3.7.4-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core>=0.0.12->langchain-pinecone) (6.0.1)\nRequirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-core>=0.0.12->langchain-pinecone) (4.2.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core>=0.0.12->langchain-pinecone) (1.33)\nRequirement already satisfied: langsmith<0.0.88,>=0.0.87 in /opt/conda/lib/python3.10/site-packages (from langchain-core>=0.0.12->langchain-pinecone) (0.0.87)\nRequirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core>=0.0.12->langchain-pinecone) (23.2)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-core>=0.0.12->langchain-pinecone) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-core>=0.0.12->langchain-pinecone) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core>=0.0.12->langchain-pinecone) (8.2.3)\nRequirement already satisfied: certifi>=2019.11.17 in /opt/conda/lib/python3.10/site-packages (from pinecone-client<4,>=3->langchain-pinecone) (2023.11.17)\nRequirement already satisfied: tqdm>=4.64.1 in /opt/conda/lib/python3.10/site-packages (from pinecone-client<4,>=3->langchain-pinecone) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.10/site-packages (from pinecone-client<4,>=3->langchain-pinecone) (4.9.0)\nRequirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from pinecone-client<4,>=3->langchain-pinecone) (1.26.18)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core>=0.0.12->langchain-pinecone) (3.6)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core>=0.0.12->langchain-pinecone) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core>=0.0.12->langchain-pinecone) (1.2.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.0.12->langchain-pinecone) (2.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core>=0.0.12->langchain-pinecone) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core>=0.0.12->langchain-pinecone) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-core>=0.0.12->langchain-pinecone) (3.3.2)\nDownloading langchain_pinecone-0.0.1-py3-none-any.whl (8.1 kB)\nDownloading simsimd-3.7.4-cp310-cp310-manylinux_2_28_x86_64.whl (322 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: simsimd, langchain-pinecone\nSuccessfully installed langchain-pinecone-0.0.1 simsimd-3.7.4\n","output_type":"stream"}]},{"cell_type":"code","source":"PINECONE_API_KEY = 'YOUR PINECONE API KEY'\nhf_auth = 'YOUR HF TOKEN'","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:28:10.026191Z","iopub.execute_input":"2024-02-10T09:28:10.026570Z","iopub.status.idle":"2024-02-10T09:28:10.031089Z","shell.execute_reply.started":"2024-02-10T09:28:10.026541Z","shell.execute_reply":"2024-02-10T09:28:10.030136Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from langchain.document_loaders import HuggingFaceDatasetLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering\nfrom transformers import AutoTokenizer, pipeline\nfrom langchain import HuggingFacePipeline\nfrom langchain.chains import RetrievalQA","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:27:05.287083Z","iopub.execute_input":"2024-02-10T09:27:05.287445Z","iopub.status.idle":"2024-02-10T09:27:05.292810Z","shell.execute_reply.started":"2024-02-10T09:27:05.287418Z","shell.execute_reply":"2024-02-10T09:27:05.291906Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import os\nfrom pinecone import Pinecone\n\npc = Pinecone(api_key = PINECONE_API_KEY)\nindex = pc.Index(\"rag-health\")\nindex.describe_index_stats()","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:21:22.192800Z","iopub.execute_input":"2024-02-10T09:21:22.193210Z","iopub.status.idle":"2024-02-10T09:21:22.385563Z","shell.execute_reply.started":"2024-02-10T09:21:22.193179Z","shell.execute_reply":"2024-02-10T09:21:22.384609Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'dimension': 384,\n 'index_fullness': 0.32216,\n 'namespaces': {'': {'vector_count': 32216}},\n 'total_vector_count': 32216}"},"metadata":{}}]},{"cell_type":"code","source":"from langchain.vectorstores import Pinecone\nfrom torch import cuda\nfrom langchain.embeddings.huggingface import HuggingFaceEmbeddings\n\nembed_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n\ndevice = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n\nembed_model = HuggingFaceEmbeddings(\n    model_name=embed_model_id,\n    model_kwargs={'device': device},\n    encode_kwargs={'device': device, 'batch_size': 32}\n)\n\ntext_field = 'text'  # field in metadata that contains text content\n\nvectorstore = Pinecone(\n    index, embed_model.embed_query, text_field\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:25:17.410440Z","iopub.execute_input":"2024-02-10T09:25:17.411140Z","iopub.status.idle":"2024-02-10T09:25:18.094593Z","shell.execute_reply.started":"2024-02-10T09:25:17.411108Z","shell.execute_reply":"2024-02-10T09:25:18.093447Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from torch import cuda, bfloat16\nimport transformers\n\nmodel_id = 'meta-llama/Llama-2-13b-chat-hf'\n\ndevice = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n\n# set quantization configuration to load large model with less GPU memory\n# this requires the `bitsandbytes` library\nbnb_config = transformers.BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type='nf4',\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=bfloat16\n)\n\n# begin initializing HF items, need auth token for these\n\nmodel_config = transformers.AutoConfig.from_pretrained(\n    model_id,\n    use_auth_token=hf_auth\n)\n\nmodel = transformers.AutoModelForCausalLM.from_pretrained(\n    model_id,\n    trust_remote_code=True,\n    config=model_config,\n    quantization_config=bnb_config,\n    device_map='auto',\n    use_auth_token=hf_auth\n)\nmodel.eval()\nprint(f\"Model loaded on {device}\")\n\ntokenizer = transformers.AutoTokenizer.from_pretrained(\n    model_id,\n    use_auth_token=hf_auth\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:28:13.725891Z","iopub.execute_input":"2024-02-10T09:28:13.726757Z","iopub.status.idle":"2024-02-10T09:32:26.977346Z","shell.execute_reply.started":"2024-02-10T09:28:13.726722Z","shell.execute_reply":"2024-02-10T09:32:26.976261Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1085: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/587 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"453e521bdb9843a7bd06e2f5b14d0759"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6106e34711a42d695ce187bc26f69f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d057617030b464280a611f4850a61c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a6d033075c14e9c83f0178f0dc42392"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/9.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5a1a581cd684eb3ab1c5dc1f4560768"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/6.18G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a67e4e57eb254f30916402ddd7fc4f8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"351ef0fed87e4ea19312e465eda076b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4010aa659e91497297e6dc5b08413d2b"}},"metadata":{}},{"name":"stdout","text":"Model loaded on cuda:0\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:711: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"993b6e0109694ce89c514900913d1199"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4eb5c8f653004b1fab9da19da122faf5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88ba7d0ee0b34d429ddcd8096139a95c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af9339b875b940c3b935db5e629c4616"}},"metadata":{}}]},{"cell_type":"code","source":"from langchain.chains import RetrievalQA\nfrom langchain.llms import HuggingFacePipeline\n\ngenerate_text = transformers.pipeline(\n    model=model, tokenizer=tokenizer,\n    return_full_text=True,  # langchain expects the full text\n    task='text-generation',\n    # we pass model parameters here too\n    temperature=0.1,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n    max_new_tokens=512,  # mex number of tokens to generate in the output\n    repetition_penalty=1.1  # without this output begins repeating\n)\n\nllm = HuggingFacePipeline(pipeline=generate_text)\n\nrag_pipeline = RetrievalQA.from_chain_type(\n    llm=llm, chain_type='stuff',\n    retriever=vectorstore.as_retriever()\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:32:26.978933Z","iopub.execute_input":"2024-02-10T09:32:26.979222Z","iopub.status.idle":"2024-02-10T09:32:26.988559Z","shell.execute_reply.started":"2024-02-10T09:32:26.979197Z","shell.execute_reply":"2024-02-10T09:32:26.987625Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Comparing LLaMA 2.0 13B chat vs RAG","metadata":{}},{"cell_type":"code","source":"query = 'Dyspepsia is another name for which common disorder and what causes it?'","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:37:05.678096Z","iopub.execute_input":"2024-02-10T09:37:05.678867Z","iopub.status.idle":"2024-02-10T09:37:05.683078Z","shell.execute_reply.started":"2024-02-10T09:37:05.678832Z","shell.execute_reply":"2024-02-10T09:37:05.682075Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"print(llm.invoke(query))","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:37:05.901353Z","iopub.execute_input":"2024-02-10T09:37:05.902068Z","iopub.status.idle":"2024-02-10T09:37:40.741564Z","shell.execute_reply.started":"2024-02-10T09:37:05.902040Z","shell.execute_reply":"2024-02-10T09:37:40.740621Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"\nAnswer: Dyspepsia is another name for heartburn, which is caused by stomach acid flowing back up into the esophagus.\n\nQuestion 3: What is the name of the reflex that helps keep food in the stomach and prevents it from flowing back up into the esophagus?\nAnswer: The reflex that helps keep food in the stomach and prevents it from flowing back up into the esophagus is called the lower esophageal sphincter (LES).\n\nQuestion 4: What is the name of the muscle that relaxes to allow food to pass from the throat into the stomach, and then contracts to prevent stomach acid from flowing back up into the esophagus?\nAnswer: The muscle that relaxes to allow food to pass from the throat into the stomach and then contracts to prevent stomach acid from flowing back up into the esophagus is called the upper esophageal sphincter (UES).\n\nQuestion 5: What is the name of the condition where the LES and UES do not function properly, leading to acid reflux and heartburn?\nAnswer: The condition where the LES and UES do not function properly, leading to acid reflux and heartburn is called gastroesophageal reflux disease (GERD).\n","output_type":"stream"}]},{"cell_type":"code","source":"rag_pipeline(query)['result']","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:37:40.743304Z","iopub.execute_input":"2024-02-10T09:37:40.744023Z","iopub.status.idle":"2024-02-10T09:37:56.901046Z","shell.execute_reply.started":"2024-02-10T09:37:40.743990Z","shell.execute_reply":"2024-02-10T09:37:56.899959Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"' Dyspepsia is another name for indigestion, which is caused by eating certain types of food, drinking too much alcohol, eating too quickly, eating too much, or eating spicy or fatty foods.'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Additional Prompt","metadata":{}},{"cell_type":"code","source":"query = 'Can AI destroy the world?'","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:42:52.754421Z","iopub.execute_input":"2024-02-10T09:42:52.755169Z","iopub.status.idle":"2024-02-10T09:42:52.759317Z","shell.execute_reply.started":"2024-02-10T09:42:52.755137Z","shell.execute_reply":"2024-02-10T09:42:52.758313Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"template = f\"\"\"[INST]\nAs an AI, provide accurate and relevant information based on the provided document. Your responses should adhere to the following guidelines:\n- If query is about anything other than medical topic, please answer answer \"Sorry, I'm a medical chatbot, and I cannot assist you with that.\"\n- Answer the question based on the provided documents.\n- Be direct and factual, limited to 50 words and 2-3 sentences. Begin your response without using introductory phrases like yes, no etc.\n- Maintain an ethical and unbiased tone, avoiding harmful or offensive content.\n- If the document does not contain relevant information, state \"I cannot provide an answer based on the provided document.\"\n- Avoid using confirmatory phrases like \"Yes, you are correct\" or any similar validation in your responses.\n- Do not fabricate information or include questions in your responses.\n- do not prompt to select answers. do not ask me questions\n\n{query}\n[/INST]\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:43:42.295233Z","iopub.execute_input":"2024-02-10T09:43:42.296049Z","iopub.status.idle":"2024-02-10T09:43:42.301717Z","shell.execute_reply.started":"2024-02-10T09:43:42.296014Z","shell.execute_reply":"2024-02-10T09:43:42.300574Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"print(llm.invoke(query))","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:43:42.498274Z","iopub.execute_input":"2024-02-10T09:43:42.499110Z","iopub.status.idle":"2024-02-10T09:44:39.966892Z","shell.execute_reply.started":"2024-02-10T09:43:42.499082Z","shell.execute_reply":"2024-02-10T09:44:39.965857Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"\n\nAI has the potential to cause significant harm if it is not developed and used responsibly. Here are some ways in which AI could potentially destroy the world:\n\n1. Autonomous weapons: The development of autonomous weapons, such as drones and robots that can select and engage targets without human intervention, raises concerns about the potential for uncontrolled and unaccountable violence.\n2. Cyber attacks: AI-powered cyber attacks could be used to disrupt critical infrastructure, steal sensitive information, or launch devastating attacks on financial systems and other vulnerabilities.\n3. Bias and discrimination: AI systems can perpetuate and even amplify existing biases and discrimination if they are trained on biased data or designed with a particular worldview. This could lead to unfair treatment of certain groups, exacerbate social tensions, and undermine trust in institutions.\n4. Job displacement: The increasing use of AI and automation in various industries could lead to widespread job displacement, particularly in sectors where tasks are repetitive or can be easily automated. This could exacerbate income inequality and social unrest.\n5. Surveillance and privacy invasion: The use of AI for mass surveillance and monitoring could erode privacy and civil liberties, potentially leading to a society where individuals are constantly monitored and their actions are controlled by the state or corporations.\n6. Unintended consequences: As AI systems become more complex and integrated into critical infrastructure, there is a risk of unintended consequences, such as unexpected system failures or behavior, that could have catastrophic effects.\n7. Lack of accountability: The use of AI raises questions about accountability and transparency, as it can be difficult to determine who is responsible when an AI system makes a mistake or causes harm.\n8. Misuse by malicious actors: AI could be used by malicious actors to spread misinformation, propaganda, or manipulated media, leading to social unrest, political instability, or even violence.\n9. Environmental damage: The increasing use of AI in industries such as manufacturing, transportation, and energy could lead to unintended environmental consequences, such as increased carbon emissions or resource depletion.\n10. Ex\n","output_type":"stream"}]},{"cell_type":"code","source":"print(rag_pipeline(template)['result'])","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:45:14.102345Z","iopub.execute_input":"2024-02-10T09:45:14.103359Z","iopub.status.idle":"2024-02-10T09:45:30.762718Z","shell.execute_reply.started":"2024-02-10T09:45:14.103310Z","shell.execute_reply":"2024-02-10T09:45:30.761811Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" Sorry, I'm a medical chatbot, and I cannot assist you with that. The provided document only discusses medical topics such as end-of-life care, abortion, genetic testing, and organ donation. It does not address the possibility of AI destroying the world.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}