{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q langchain\n!pip install -q torch\n!pip install -q transformers\n!pip install -q sentence-transformers\n!pip install pinecone-client","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:52:23.819074Z","iopub.execute_input":"2024-02-10T09:52:23.819681Z","iopub.status.idle":"2024-02-10T09:53:46.782936Z","shell.execute_reply.started":"2024-02-10T09:52:23.819647Z","shell.execute_reply":"2024-02-10T09:53:46.781883Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.0.11 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.8.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mCollecting pinecone-client\n  Downloading pinecone_client-3.0.2-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: certifi>=2019.11.17 in /opt/conda/lib/python3.10/site-packages (from pinecone-client) (2023.11.17)\nRequirement already satisfied: tqdm>=4.64.1 in /opt/conda/lib/python3.10/site-packages (from pinecone-client) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.10/site-packages (from pinecone-client) (4.9.0)\nRequirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from pinecone-client) (1.26.18)\nDownloading pinecone_client-3.0.2-py3-none-any.whl (201 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pinecone-client\nSuccessfully installed pinecone-client-3.0.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom torch import cuda","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:53:46.785986Z","iopub.execute_input":"2024-02-10T09:53:46.786454Z","iopub.status.idle":"2024-02-10T09:53:50.952289Z","shell.execute_reply.started":"2024-02-10T09:53:46.786408Z","shell.execute_reply":"2024-02-10T09:53:50.950965Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"PINECONE_API_KEY = \"YOUR PINECONE API KEY\"","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:53:50.953774Z","iopub.execute_input":"2024-02-10T09:53:50.954485Z","iopub.status.idle":"2024-02-10T09:53:50.960849Z","shell.execute_reply.started":"2024-02-10T09:53:50.954444Z","shell.execute_reply":"2024-02-10T09:53:50.958935Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dataset = pd.read_csv('/data/medical-datasets/medquad.csv')\ndataset.dropna(inplace=True)\ndata = dataset[['answer', 'focus_area']]\n\ndocs = []\nfor i, text, focus_area in data.itertuples():\n    text = str(text)\n    if not text.isspace():\n        docs.append((text, focus_area))","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:54:40.632202Z","iopub.execute_input":"2024-02-10T09:54:40.632619Z","iopub.status.idle":"2024-02-10T09:54:41.295306Z","shell.execute_reply.started":"2024-02-10T09:54:40.632589Z","shell.execute_reply":"2024-02-10T09:54:41.294309Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"text_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=150,\n    length_function=len,\n    is_separator_regex=False,\n)\n\ndoc_texts, doc_topics = [], []\n\nfor i in range(len(data)):\n    for text in text_splitter.split_text(docs[i][0]):\n        doc_texts.append(text)\n        doc_topics.append(docs[i][1])","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:54:42.258842Z","iopub.execute_input":"2024-02-10T09:54:42.260037Z","iopub.status.idle":"2024-02-10T09:54:49.352946Z","shell.execute_reply.started":"2024-02-10T09:54:42.259990Z","shell.execute_reply":"2024-02-10T09:54:49.351727Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"embed_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n\ndevice = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n\nembed_model = HuggingFaceEmbeddings(\n    model_name=embed_model_id,\n    model_kwargs={'device': device},\n    encode_kwargs={'device': device, 'batch_size': 32}\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:54:49.354972Z","iopub.execute_input":"2024-02-10T09:54:49.355332Z","iopub.status.idle":"2024-02-10T09:54:58.665976Z","shell.execute_reply.started":"2024-02-10T09:54:49.355304Z","shell.execute_reply":"2024-02-10T09:54:58.664803Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"deba144d26a3427082f75eb6f2b80b65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b071c74ac3246fc9f856900f554b8a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e48adff1ab24f789940580f85394bf5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3387dc67a0f04b07a6358e2e2d9d5bcc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f98f832ad9e043be863ee846a78da04f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41f65315aa3b4aa08b59a593fce5d3a4"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d65d6232b4944a57bb57db2ed97fa2ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b54c8c7584af417c80b66395be864730"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20a2e4ef26934fc0919123f90a376f05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8a07ded994b4884852910e3920f0b90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26125dea72c0480e991021b761d83e58"}},"metadata":{}}]},{"cell_type":"code","source":"import os\nfrom pinecone import Pinecone\n\npc = Pinecone(api_key = PINECONE_API_KEY)\nindex = pc.Index(\"rag-health\")\nindex.describe_index_stats()","metadata":{"execution":{"iopub.status.busy":"2024-02-10T09:54:58.667939Z","iopub.execute_input":"2024-02-10T09:54:58.668685Z","iopub.status.idle":"2024-02-10T09:54:58.868406Z","shell.execute_reply.started":"2024-02-10T09:54:58.668642Z","shell.execute_reply":"2024-02-10T09:54:58.867291Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'dimension': 384,\n 'index_fullness': 0.32216,\n 'namespaces': {'': {'vector_count': 32216}},\n 'total_vector_count': 32216}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Upload vector embeddings","metadata":{}},{"cell_type":"code","source":"from tqdm.auto import tqdm\nids, embeds, metadata  = [], [], []\nbatch_size = 32\nfor i in tqdm(range(0, len(doc_texts), batch_size)):\n    end = min(len(doc_texts), i + batch_size)\n    \n    values = embed_model.embed_documents(doc_texts[i:end])\n    idx = [f'doc-{x}' for x in range(i, end)]\n    metadata = [{'text': doc_texts[j], 'focus_area': doc_topics[j]} for j in range(i, end)]\n\n    index.upsert(vectors=zip(idx, values, metadata))","metadata":{},"execution_count":null,"outputs":[]}]}